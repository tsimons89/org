* Eco Feature Project Notes
** Creating features from other features
   Because the features are simply linear filters, the output of some filters can be used for others.
*** Creating every possible filtered image
    To speed up testing and training I thought that I could create filtered result for every possible filter that could exists.
    By limiting the genomes of the filters to a cap of 5,5,1,1 I still get good results and there are only 144 different possibilities.
** Testing every filter instead of random evolution 
   With a cap of 5,5,1,1 for the genome (x_blur,y_blur,x_diff,y_diff) there are only 144 possibilities. 
   Maybe it would improve performance to just check every possibility.
*** Random sampling
    Much of the eco feature algorithm uses random. I think it is used to reduce over fitting.
*** New algorithm
**** How to determine which filter is best
     The genetic algorithm used a smaller test set from the data set to determine fitness.
     Could I use the gini impurity?
     Maybe the size of the tree?
*** Profile the training time (filter and random forest)
    On i7 desktop with the fish data set, image processing takes an average of 15,000 cycles, where training the forest (5 trees 5 deep) takes about 53,000 cycles.
** Gini heat map
   Could I use the gini purity measure to figure out which 
   
*** TODO Create gini heat map
** Using smaller Forests
*** Results
#+PLOT: title:"Nodes vs Accuracy" ind:4 deps:(5)
#+TBLNAME:Differing Eco Parameters
| Creatures | Trees | Depth | Nodes | Accuracy |
|-----------+-------+-------+-------+----------|
|         5 |     1 |     2 |    40 | 0.570866 |
|         5 |     2 |     2 |    75 | 0.602362 |
|        10 |     1 |     2 |    80 | 0.779528 |
|         5 |     1 |     3 |    80 |  0.80315 |
|        10 |     2 |     2 |   150 | 0.791339 |
|         5 |     2 |     3 |   151 | 0.759843 |
|        10 |     1 |     3 |   158 | 0.885827 |
|        20 |     1 |     2 |   160 | 0.818898 |
|         5 |     5 |     2 |   180 | 0.708661 |
|         5 |     1 |     5 |   216 | 0.846457 |
|        30 |     1 |     2 |   240 | 0.858268 |
|        10 |     2 |     3 |   292 | 0.846457 |
|        20 |     2 |     2 |   298 | 0.834646 |
|        20 |     1 |     3 |   310 | 0.913386 |
|        40 |     1 |     2 |   320 | 0.917323 |
|         5 |     1 |    20 |   324 | 0.870079 |
|         5 |     1 |    15 |   344 | 0.901575 |
|         5 |    10 |     2 |   351 | 0.728346 |
|         5 |     1 |    20 |   352 | 0.850394 |
|        10 |     5 |     2 |   358 | 0.818898 |
|         5 |     5 |     3 |   368 |  0.84252 |
|         5 |     2 |     5 |   415 | 0.862205 |
|        10 |     1 |     5 |   430 | 0.925197 |
|        30 |     2 |     2 |   448 | 0.850394 |
|        30 |     1 |     3 |   474 |  0.92126 |
|         5 |    15 |     2 |   530 |  0.76378 |
|        20 |     2 |     3 |   600 | 0.877953 |
|        40 |     2 |     2 |   600 | 0.885827 |
|        40 |     1 |     3 |   624 | 0.917323 |
|         5 |     2 |    15 |   647 | 0.874016 |
|         5 |     2 |    20 |   655 | 0.850394 |
|        10 |     1 |    15 |   680 | 0.933071 |
|         5 |    20 |     2 |   705 | 0.720472 |
|        10 |    10 |     2 |   710 | 0.850394 |
|         5 |     2 |    20 |   717 | 0.838583 |
|        20 |     5 |     2 |   720 | 0.877953 |
|        10 |     1 |    20 |   726 | 0.905512 |
|        10 |     5 |     3 |   736 | 0.885827 |
|        10 |     1 |    20 |   740 | 0.913386 |
|         5 |    10 |     3 |   745 | 0.874016 |
|        10 |     2 |     5 |   870 | 0.885827 |
|        30 |     2 |     3 |   894 | 0.948819 |
|        20 |     1 |     5 |   926 | 0.940945 |
|         5 |     5 |     5 |  1040 | 0.925197 |
|        10 |    15 |     2 |  1060 | 0.771654 |
|        30 |     5 |     2 |  1076 | 0.917323 |
|         5 |    15 |     3 |  1088 | 0.866142 |
|        40 |     2 |     3 |  1192 | 0.925197 |
|        30 |     1 |     5 |  1260 | 0.956693 |
|        10 |     2 |    20 |  1344 | 0.909449 |
|        10 |    20 |     2 |  1404 | 0.893701 |
|        10 |     2 |    20 |  1408 | 0.917323 |
|        10 |     2 |    15 |  1414 |  0.88189 |
|        20 |    10 |     2 |  1418 | 0.917323 |
|         5 |    20 |     3 |  1435 | 0.905512 |
|        40 |     5 |     2 |  1440 | 0.917323 |
|        20 |     1 |    20 |  1472 | 0.944882 |
|        20 |     1 |    15 |  1474 | 0.952756 |
|        10 |    10 |     3 |  1478 | 0.940945 |
|        20 |     1 |    20 |  1478 | 0.948819 |
|        20 |     5 |     3 |  1480 | 0.944882 |
|         5 |     5 |    20 |  1666 | 0.940945 |
|         5 |     5 |    15 |  1682 | 0.944882 |
|        20 |     2 |     5 |  1714 | 0.948819 |
|         5 |     5 |    20 |  1754 | 0.944882 |
|        40 |     1 |     5 |  1792 | 0.964567 |
|        10 |     5 |     5 |  2048 | 0.992126 |
|         5 |    10 |     5 |  2075 | 0.933071 |
|        20 |    15 |     2 |  2114 | 0.901575 |
|        30 |    10 |     2 |  2118 | 0.933071 |
|        10 |    15 |     3 |  2188 | 0.944882 |
|        30 |     5 |     3 |  2202 | 0.964567 |
|        30 |     1 |    20 |  2268 | 0.956693 |
|        30 |     1 |    20 |  2282 | 0.980315 |
|        30 |     1 |    15 |  2288 | 0.964567 |
|        30 |     2 |     5 |  2568 | 0.944882 |
|        20 |    20 |     2 |  2814 | 0.889764 |
|        40 |    10 |     2 |  2830 | 0.952756 |
|        20 |     2 |    15 |  2868 | 0.937008 |
|        10 |    20 |     3 |  2890 | 0.925197 |
|        20 |     2 |    20 |  2898 | 0.948819 |
|        20 |     2 |    20 |  2900 | 0.944882 |
|        40 |     5 |     3 |  2908 | 0.944882 |
|        20 |    10 |     3 |  2950 | 0.952756 |
|         5 |    15 |     5 |  2980 | 0.952756 |
|        40 |     1 |    15 |  3028 | 0.952756 |
|        40 |     1 |    20 |  3058 | 0.964567 |
|        40 |     1 |    20 |  3138 | 0.964567 |
|        30 |    15 |     2 |  3172 | 0.897638 |
|        40 |     2 |     5 |  3246 | 0.956693 |
|         5 |    10 |    20 |  3535 | 0.952756 |
|        10 |     5 |    20 |  3600 | 0.952756 |
|        10 |     5 |    20 |  3636 |  0.96063 |
|         5 |    10 |    15 |  3711 | 0.952756 |
|        10 |     5 |    15 |  3756 | 0.972441 |
|         5 |    10 |    20 |  3865 | 0.956693 |
|        10 |    10 |     5 |  4118 | 0.964567 |
|         5 |    20 |     5 |  4153 | 0.948819 |
|        30 |    20 |     2 |  4222 | 0.956693 |
|        40 |    15 |     2 |  4230 | 0.948819 |
|        30 |     2 |    20 |  4354 | 0.948819 |
|        20 |     5 |     5 |  4358 | 0.956693 |
|        30 |    10 |     3 |  4366 | 0.964567 |
|        20 |    15 |     3 |  4368 | 0.937008 |
|        30 |     2 |    20 |  4374 | 0.948819 |
|        30 |     2 |    15 |  4458 | 0.976378 |
|         5 |    15 |    15 |  5130 | 0.964567 |
|         5 |    15 |    20 |  5348 | 0.956693 |
|         5 |    15 |    20 |  5534 | 0.964567 |
|        40 |    20 |     2 |  5622 |  0.92126 |
|        20 |    20 |     3 |  5764 | 0.968504 |
|        40 |    10 |     3 |  5808 |  0.96063 |
|        40 |     2 |    20 |  6052 | 0.964567 |
|        40 |     2 |    20 |  6120 | 0.968504 |
|        40 |     2 |    15 |  6200 | 0.956693 |
|        10 |    15 |     5 |  6318 | 0.976378 |
|        30 |     5 |     5 |  6340 | 0.976378 |
|        30 |    15 |     3 |  6580 | 0.968504 |
|         5 |    20 |    15 |  6597 | 0.964567 |
|         5 |    20 |    20 |  6975 | 0.956693 |
|        10 |    10 |    20 |  7110 | 0.968504 |
|        10 |    10 |    20 |  7176 | 0.968504 |
|        10 |    10 |    15 |  7184 | 0.980315 |
|         5 |    20 |    20 |  7227 |  0.96063 |
|        20 |     5 |    20 |  7354 | 0.972441 |
|        20 |     5 |    15 |  7404 | 0.976378 |
|        20 |     5 |    20 |  7494 | 0.964567 |
|        10 |    20 |     5 |  8170 | 0.968504 |
|        20 |    10 |     5 |  8442 | 0.976378 |
|        40 |     5 |     5 |  8610 | 0.972441 |
|        40 |    15 |     3 |  8620 | 0.968504 |
|        30 |    20 |     3 |  8678 | 0.968504 |
|        10 |    15 |    20 | 10576 | 0.984252 |
|        10 |    15 |    15 | 10658 | 0.976378 |
|        30 |     5 |    15 | 11100 | 0.972441 |
|        30 |     5 |    20 | 11124 | 0.972441 |
|        10 |    15 |    20 | 11396 | 0.980315 |
|        40 |    20 |     3 | 11578 | 0.972441 |
|        30 |     5 |    20 | 11684 | 0.984252 |
|        20 |    15 |     5 | 12278 | 0.980315 |
|        30 |    10 |     5 | 12568 | 0.972441 |
|        10 |    20 |    20 | 14302 | 0.972441 |
|        20 |    10 |    15 | 14958 | 0.972441 |
|        40 |     5 |    20 | 15126 | 0.972441 |
|        20 |    10 |    20 | 15156 | 0.964567 |
|        40 |     5 |    20 | 15226 | 0.964567 |
|        20 |    10 |    20 | 15432 | 0.988189 |
|        10 |    20 |    15 | 15608 | 0.964567 |
|        10 |    20 |    20 | 15688 | 0.968504 |
|        40 |     5 |    15 | 15688 | 0.980315 |
|        20 |    20 |     5 | 16768 | 0.968504 |
|        40 |    10 |     5 | 16806 | 0.964567 |
|        30 |    15 |     5 | 18360 | 0.980315 |
|        20 |    15 |    15 | 22152 | 0.980315 |
|        20 |    15 |    20 | 22252 | 0.980315 |
|        30 |    10 |    20 | 22610 | 0.972441 |
|        20 |    15 |    20 | 22656 | 0.984252 |
|        30 |    10 |    20 | 22934 | 0.984252 |
|        30 |    10 |    15 | 23030 | 0.980315 |
|        30 |    20 |     5 | 24558 | 0.984252 |
|        40 |    15 |     5 | 24678 | 0.976378 |
|        20 |    20 |    20 | 29630 | 0.972441 |
|        20 |    20 |    15 | 29992 | 0.984252 |
|        40 |    10 |    20 | 30500 | 0.980315 |
|        40 |    10 |    15 | 30644 | 0.976378 |
|        20 |    20 |    20 | 31446 | 0.980315 |
|        40 |    10 |    20 | 31634 | 0.984252 |
|        40 |    20 |     5 | 32584 | 0.980315 |
|        30 |    15 |    20 | 34670 | 0.988189 |
|        30 |    15 |    15 | 34834 | 0.980315 |
|        30 |    15 |    20 | 35198 | 0.988189 |
|        40 |    15 |    20 | 46240 | 0.980315 |
|        40 |    15 |    20 | 46492 | 0.984252 |
|        30 |    20 |    20 | 46852 | 0.988189 |
|        40 |    15 |    15 | 47136 | 0.984252 |
|        30 |    20 |    15 | 47560 | 0.980315 |
|        30 |    20 |    20 | 48358 | 0.988189 |
|        40 |    20 |    15 | 63050 | 0.988189 |
|        40 |    20 |    20 | 63152 | 0.984252 |
|        40 |    20 |    20 | 64508 | 0.988189 |


| Creatures | Trees | Depth | Nodes | Accuracy |
|-----------+-------+-------+-------+----------|
|        30 |     5 |     5 |  6528 |     97.6 |
|        20 |     5 |     5 |  4194 |     97.2 |
|        30 |     3 |     5 |  3826 |     97.2 |
|        30 |     2 |     5 |  2582 |          |
|        10 |     5 |     5 |  2046 |     95.6 |
|         5 |     5 |     5 |  1018 |     94.5 |
** Using the same data set for training and testing creatures
   It seems that results are generally better and more consistant when data sets aren't split into train and hold sets
** Evaluation
   Get statistics of many training runs to see the tade
** Hardware Design
*** Random Forest
**** Tree Design
     Because the hardware will be fixed, I will build the trees with the maximum number of nodes.
     There will be no leaves that terminate a branch before the maximum depth.
***** BRAM storage
      I could either store the nodes in some standard order based on their position in the tree, or I could store them in the order that they will be produced by the eco feature which is sorted by variable number
      
***** Resources Needed
      #+TBLNAME:Estimated Bits for Node
      | Data  | Range     | Bits |
      |-------+-----------+------|
      | Var   | 0 - 10,00 |   14 |
      | Value | 22 +/-    |   21 |
      | Id    | 0 - 30    |    6 |
      |-------+-----------+------|
      | Total |           |   41 |
      #+TBLFM: $3=vsum(@2..@-1)

      My Kintex has 445 BRAMs with 36Kb each. I could probably just have every tree fit into a BRAM.
      
